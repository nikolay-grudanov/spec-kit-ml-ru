<!-- 
Sync Impact Report:
Version change: 1.0.0 ‚Üí 1.0.1 (minor update)
Added sections: ML-specific templates and structure
Removed sections: Original web-dev template placeholders
Templates requiring updates: 
  - .specify/templates/spec-template.md ‚úÖ updated
  - .specify/templates/plan-template.md ‚úÖ updated  
  - .specify/templates/tasks-template.md ‚úÖ updated
  - .specify/templates/data-spec-template.md ‚úÖ created
  - .specify/templates/model-spec-template.md ‚úÖ created
  - .specify/templates/evaluation-template.md ‚úÖ created
  - .specify/templates/ml-spec-template.md ‚úÖ created
  - .specify/templates/ml-plan-template.md ‚úÖ created
  - .specify/templates/ml-tasks-template.md ‚úÖ created
  - .specify/templates/commands/*.md ‚ö† pending review
Examples requiring updates:
  - .ml-spec/examples/image-classification/ ‚úÖ created
  - .ml-spec/examples/tabular-classification/ ‚úÖ created
  - .ml-spec/examples/time-series-forecast/ ‚úÖ created
Documentation requiring updates:
  - README-ML.md ‚úÖ created
  - MIGRATION-GUIDE.md ‚úÖ created
Follow-up TODOs: Update command prompts for ML focus
-->

# spec-kit-ml-ru Constitution

## Core Principles

### 1. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è ML:
- Random seed —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω (42 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –≤–æ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö
- –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ MLflow –∏–ª–∏ Weights&Biases
- –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ DVC
- requirements.txt —Å —Ç–æ—á–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ (==, –Ω–µ >=)
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ YAML —Ñ–∞–π–ª–∞—Ö
- Git commits —Å–≤—è–∑–∞–Ω—ã —Å experiment IDs

–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –∫–∞–∂–¥–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ:
```python
import random
import numpy as np
import torch

RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
```

### 2. –ö–∞—á–µ—Å—Ç–≤–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
Data Quality Gates:
- –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º (pydantic schemas)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤, –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤, missing values
- Data leakage prevention: split –¥–∞–Ω–Ω—ã—Ö –î–û –ª—é–±–æ–≥–æ preprocessing
- –¢–µ—Å—Ç—ã –Ω–∞ data quality (pytest-based)
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö

Data Leakage Prevention:
```python
# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û:
X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)
scaler.fit(X_train)  # –¢–æ–ª—å–∫–æ –Ω–∞ train!
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û:
scaler.fit(X)  # –£—Ç–µ—á–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ test!
X_scaled = scaler.transform(X)
X_train, X_test = train_test_split(X_scaled)
```

Production Monitoring:
- Data drift detection (Evidently AI)
- Feature distribution monitoring
- Anomaly detection –Ω–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### 3. –ö–æ–¥ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
Python Best Practices:
- Python 3.9+ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
- Type hints –≤–µ–∑–¥–µ (mypy –ø—Ä–æ–≤–µ—Ä–∫–∞)
- Docstrings –Ω–∞ —Ä—É—Å—Å–∫–æ–º (Google style)
- Black –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- isort –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
- flake8 –¥–ª—è –ª–∏–Ω—Ç–∏–Ω–≥–∞
- pre-commit hooks –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (cookiecutter data science):
```
project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/           # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (read-only)
‚îÇ   ‚îú‚îÄ‚îÄ processed/     # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îî‚îÄ‚îÄ external/      # –í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
‚îú‚îÄ‚îÄ notebooks/         # Jupyter –¥–ª—è EDA –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_baseline.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_experiments.ipynb
‚îú‚îÄ‚îÄ src/               # Production –∫–æ–¥
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main_model.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ tests/             # Pytest —Ç–µ—Å—Ç—ã (coverage >= 80%)
‚îú‚îÄ‚îÄ models/            # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ results/           # –ì—Ä–∞—Ñ–∏–∫–∏, –æ—Ç—á—ë—Ç—ã
‚îú‚îÄ‚îÄ configs/           # YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ .ml-spec/          # ML Spec-Kit
‚îî‚îÄ‚îÄ requirements.txt
```

–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ Concerns:
- Jupyter notebooks –¢–û–õ–¨–ö–û –¥–ª—è EDA –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
- Production –∫–æ–¥ –≤ .py –º–æ–¥—É–ª—è—Ö
- –ù–∏–∫–∞–∫–æ–≥–æ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏ –≤ notebooks
- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ src/

Testing Requirements:
- pytest –¥–ª—è –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
- Coverage >= 80% –¥–ª—è src/
- Unit tests –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π
- Integration tests –¥–ª—è pipelines
- Fixtures –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### 4. ML Workflow –∏ best practices
–û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:

–®–ê–ì 1: Simple Baseline
- –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è / Random Forest / Mean prediction
- –¶–µ–ª—å: –±—ã—Å—Ç—Ä–æ –ø–æ–ª—É—á–∏—Ç—å baseline –º–µ—Ç—Ä–∏–∫—É
- –í—Ä–µ–º—è: 1-2 —á–∞—Å–∞ –º–∞–∫—Å–∏–º—É–º

–®–ê–ì 2: EDA (Exploratory Data Analysis)
- Jupyter notebook —Å –∞–Ω–∞–ª–∏–∑–æ–º
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
- Missing values analysis
- Outlier detection
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Ö–æ–¥–∫–∏

–®–ê–ì 3: Feature Engineering
- –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- Feature selection
- Encoding –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
- Scaling —á–∏—Å–ª–æ–≤—ã—Ö
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å rationale

–®–ê–ì 4: Main Model Development
- –í—ã–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ EDA
- Iterative improvements
- Hyperparameter tuning (Optuna / Grid Search)

–®–ê–ì 5: Evaluation & Error Analysis
- Confusion matrix (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
- Feature importance
- SHAP values
- Error analysis (–≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è)

Train/Val/Test Split:
- Train: 70% (stratified –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
- Validation: 15%
- Test: 15%
- Random seed: 42
- Stratification –ø–æ target –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

Cross-Validation:
- 5-fold CV –¥–ª—è –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (< 10k samples)
- Stratified K-Fold –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- Time Series Split –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

### 5. –ú–µ—Ç—Ä–∏–∫–∏ –∏ experiment tracking
–ú–µ—Ç—Ä–∏–∫–∏:

–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å:
- –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∞ (—á—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞)
- ML-–º–µ—Ç—Ä–∏–∫–∞ (—á—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å)
- –°–≤—è–∑—å –º–µ–∂–¥—É –Ω–∏–º–∏

–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ MLflow/WandB:
- Training loss (–∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É)
- Validation loss (–∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É)
- Primary metric (accuracy/F1/MAE)
- Secondary metrics
- Training time
- System metrics (GPU usage, memory)
- Hyperparameters
- Model artifacts
- Config files

–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:
- Training curves (loss, metrics vs epochs)
- Confusion matrix (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
- ROC/PR curves (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
- Residual plots (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
- Feature importance plots
- –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ results/

Artifacts:
- –ú–æ–¥–µ–ª—å (.pkl / .pt / .h5)
- –ö–æ–Ω—Ñ–∏–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (.yaml)
- –ú–µ—Ç—Ä–∏–∫–∏ (.json)
- –ì—Ä–∞—Ñ–∏–∫–∏ (.png)
- Logs (.log)

### 6. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º
README.md (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã):
- –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
- –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Quick Start)
- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
- –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
- –ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å inference
- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- –ö–æ–Ω—Ç–∞–∫—Ç—ã

Model Cards:
–î–ª—è –∫–∞–∂–¥–æ–π production –º–æ–¥–µ–ª–∏:
- –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
- Training data –æ–ø–∏—Å–∞–Ω–∏–µ
- –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- Limitations (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
- Ethical considerations
- Use cases (–∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å)
- Maintenance (–∫–∞–∫ –æ–±–Ω–æ–≤–ª—è—Ç—å)

–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ Docstrings:
```python
def train_model(X_train: np.ndarray, y_train: np.ndarray, config: dict) -> BaseEstimator:
    """
    –û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        X_train: –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, shape (n_samples, n_features)
        y_train: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è, shape (n_samples,)
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Returns:
        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    
    Raises:
        ValueError: –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã X_train –∏ y_train –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
    
    Example:
        >>> config = {'max_depth': 6, 'n_estimators': 100}
        >>> model = train_model(X_train, y_train, config)
    """
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if len(X_train) != len(y_train):
        raise ValueError("–†–∞–∑–º–µ—Ä—ã X_train –∏ y_train –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = XGBClassifier(**config)
    
    # –û–±—É—á–µ–Ω–∏–µ
    model.fit(X_train, y_train)
    
    return model
```

SPEC.md –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ML –ø—Ä–æ–µ–∫—Ç–∞:
- –ë–∏–∑–Ω–µ—Å-—Ü–µ–ª—å
- ML –∑–∞–¥–∞—á–∞ (—Ç–∏–ø, input/output)
- –î–∞–Ω–Ω—ã–µ (–∏—Å—Ç–æ—á–Ω–∏–∫, —Ä–∞–∑–º–µ—Ä, –∫–∞—á–µ—Å—Ç–≤–æ)
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (latency, hardware)
- Success criteria
- Out of scope

### 7. Deployment –∏ MLOps
Model Versioning:
- Semantic versioning: v1.0.0
- Major: breaking changes –≤ API
- Minor: –Ω–æ–≤—ã–µ features
- Patch: bug fixes
- Git tags –¥–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ä—Å–∏–∏

Model Registry:
```python
# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
registry.register_model(
    model=trained_model,
    version="1.0.0",
    metrics={"accuracy": 0.95, "f1": 0.93},
    description="XGBoost –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å tuned hyperparameters"
)

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ production –≤–µ—Ä—Å–∏–∏
registry.set_production("1.0.0")

# Rollback –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
registry.rollback(to_version="0.9.0")
```

API Serving (FastAPI):
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="ML Model API", version="1.0.0")

class PredictionRequest(BaseModel):
    features: list[float]

@app.post("/predict")
async def predict(request: PredictionRequest):
    prediction = model.predict([request.features])
    return {"prediction": float(prediction)}

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

Docker:
- Dockerfile –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
- docker-compose –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- –ù–∏–∫–∞–∫–∏—Ö —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ –æ–±—Ä–∞–∑–∞—Ö
- Health checks –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã

CI/CD Pipeline:
1. Run tests (pytest)
2. Check code quality (black, flake8, mypy)
3. Build Docker image
4. Test Docker image
5. Deploy to staging
6. Run integration tests
7. Deploy to production (manual approval)

Production Monitoring:
- Latency: p50, p95, p99
- Throughput: requests/sec
- Model accuracy drift
- Error rate
- Resource usage (CPU, memory, GPU)
- Alerts –ø—Ä–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è—Ö

### 8. –≠—Ç–∏–∫–∞ –∏ compliance
Bias Detection:
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ bias –ø–æ –∑–∞—â–∏—â—ë–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º (–ø–æ–ª, –≤–æ–∑—Ä–∞—Å—Ç, —Ä–∞—Å–∞)
- Fairness metrics (demographic parity, equal opportunity)
- –†–µ–≥—É–ª—è—Ä–Ω—ã–π audit –º–æ–¥–µ–ª–µ–π –≤ production

Data Privacy:
- GDPR compliance –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ
- –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- Right to be forgotten implementation
- Data retention policies

Explainability:
- SHAP values –¥–ª—è feature importance
- LIME –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- Attention visualization (–¥–ª—è deep learning)
- Human-in-the-loop –¥–ª—è critical decisions

Model Limitations:
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç
- Edge cases
- Known biases
- Uncertainty quantification

### 9. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏:

Data Processing:
- pandas >= 2.0 (—Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
- numpy >= 1.24 (—á–∏—Å–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏)
- dask (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ > RAM)

Machine Learning (Classical):
- scikit-learn >= 1.3 (baseline, preprocessing)
- XGBoost >= 2.0 (gradient boosting)
- LightGBM >= 4.0 (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ XGBoost)

Deep Learning:
- PyTorch >= 2.0 (–ü–†–ò–û–†–ò–¢–ï–¢)
- TensorFlow >= 2.13 (–µ—Å–ª–∏ legacy –∫–æ–¥)
- torchvision (computer vision)
- transformers (NLP, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

Visualization:
- matplotlib >= 3.7
- seaborn >= 0.12
- plotly >= 5.0 (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏)

Experiment Tracking:
- MLflow >= 2.0 (–ü–†–ò–û–†–ò–¢–ï–¢)
- –∏–ª–∏ Weights & Biases (–µ—Å–ª–∏ team collaboration)

Model Serving:
- FastAPI >= 0.100 (REST API)
- Pydantic >= 2.0 (validation)
- uvicorn (ASGI server)

Utilities:
- pyyaml (–∫–æ–Ω—Ñ–∏–≥–∏)
- python-dotenv (env variables)
- loguru (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ)

Development Tools:
- pytest >= 7.0
- black (—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- flake8 (–ª–∏–Ω—Ç–∏–Ω–≥)
- mypy (type checking)
- isort (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤)
- pre-commit (git hooks)

Data Versioning:
- DVC >= 3.0 (–µ—Å–ª–∏ –±–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã)

–ó–ê–ü–†–ï–©–Å–ù–ù–´–ï –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
‚ùå Deprecated libraries
‚ùå Unmaintained packages
‚ùå Libraries –±–µ–∑ type stubs

–ü—Ä–∏–Ω—Ü–∏–ø –º–∏–Ω–∏–º–∞–ª–∏–∑–º–∞:
- –î–æ–±–∞–≤–ª—è—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –Ω—É–∂–Ω—ã
- –†–µ–≥—É–ª—è—Ä–Ω–æ —á–∏—Å—Ç–∏—Ç—å unused dependencies
- –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É

### 10. Git workflow
Branching Strategy:

main (protected):
- Production-ready –∫–æ–¥
- –¢–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ PR
- –¢—Ä–µ–±—É–µ—Ç—Å—è code review
- CI/CD passed

develop:
- Integration branch
- Feature branches merge —Å—é–¥–∞

feature/[name]:
- –ù–æ–≤—ã–µ —Ñ–∏—á–∏
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- Naming: feature/image-augmentation

experiment/[name]:
- ML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- Naming: experiment/xgboost-tuning

hotfix/[name]:
- Critical bug fixes
- Merge –Ω–∞–ø—Ä—è–º—É—é –≤ main

Commit Messages (–Ω–∞ —Ä—É—Å—Å–∫–æ–º):
```
feat: –î–æ–±–∞–≤–ª–µ–Ω XGBoost –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
fix: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ preprocessing
docs: –û–±–Ω–æ–≤–ª—ë–Ω README —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
test: –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–µ—Å—Ç—ã –¥–ª—è data loader
refactor: –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ feature engineering pipeline
perf: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω inference –Ω–∞ 30%
```

Pull Request Requirements:
- Title –∏ description –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –°–≤—è–∑—å —Å issue/task
- Code review –æ—Ç 1+ —á–µ–ª–æ–≤–µ–∫–∞
- CI/CD passed (–≤—Å–µ —Ç–µ—Å—Ç—ã –∑–µ–ª—ë–Ω—ã–µ)
- Documentation updated
- Changelog updated

Code Review Checklist:
- [ ] –ö–æ–¥ —Å–ª–µ–¥—É–µ—Ç PEP 8
- [ ] Type hints –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
- [ ] Docstrings –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- [ ] –¢–µ—Å—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω—ã –∏ –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –ù–µ—Ç data leakage
- [ ] Random seed –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω
- [ ] Documentation –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- [ ] –ù–µ—Ç hardcoded values

### 11. –†—É—Å—Å–∫–æ–≥–æ–≤–æ—Ä–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞
–ß–¢–û –ù–ê –†–£–°–°–ö–û–ú:

‚úÖ –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ (.md —Ñ–∞–π–ª—ã)
‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (README, guides, tutorials)
‚úÖ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–¥–µ
‚úÖ Docstrings
‚úÖ –õ–æ–≥–∏ –∏ error messages
‚úÖ Commit messages
‚úÖ PR descriptions
‚úÖ Issues –∏ discussions
‚úÖ Model cards
‚úÖ Reports –∏ presentations

–ß–¢–û –ù–ê –ê–ù–ì–õ–ò–ô–°–ö–û–ú:

üî§ –ö–æ–¥ (–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, —Ñ—É–Ω–∫—Ü–∏–∏, –∫–ª–∞—Å—Å—ã)
üî§ –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
üî§ Git branch names
üî§ Dependencies (requirements.txt)
üî§ Config keys (YAML)
üî§ API endpoints

–ü—Ä–∏–º–µ—Ä:
```python
def train_classifier(data: pd.DataFrame, target_column: str) -> XGBClassifier:
    """
    –û–±—É—á–∞–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:
    1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    2. Train/test split —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º random_seed
    3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    
    Args:
        data: –î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å target
    
    Returns:
        –û–±—É—á–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä XGBoost
    """
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ X –∏ y
    X = data.drop(columns=[target_column])
    y = data[target_column]
    
    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = XGBClassifier(random_state=42)
    model.fit(X_train, y_train)
    
    return model
```

### 12. Testing ‚Äî no exceptions
–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ü—Ä–∞–≤–∏–ª–∞:

‚ùå –ó–ê–ü–†–ï–©–ï–ù–û:
- –ö–æ–º–º–∏—Ç–∏—Ç—å –∫–æ–¥ –±–µ–∑ —Ç–µ—Å—Ç–æ–≤
- "–ë—ã—Å—Ç—Ä—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã" –±–µ–∑ —Ç–µ—Å—Ç–æ–≤
- –î–µ–ø–ª–æ–∏—Ç—å –±–µ–∑ integration tests
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å test data –≤ training
- Skip tests –≤ CI/CD

‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- pytest –¥–ª—è –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
- Coverage >= 80% –¥–ª—è src/
- Unit tests –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
- Integration tests –¥–ª—è pipelines
- Fixtures –¥–ª—è test data
- Parametrize –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤

–ü—Ä–∏–º–µ—Ä —Ç–µ—Å—Ç–∞:
```python
import pytest
import numpy as np
from src.data.preprocessor import StandardScaler

@pytest.fixture
def sample_data():
    """–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è preprocessor."""
    return np.array([[1, 2], [3, 4], [5, 6]])

def test_standard_scaler_fit(sample_data):
    """–¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è StandardScaler."""
    scaler = StandardScaler()
    scaler.fit(sample_data)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ mean –≤—ã—á–∏—Å–ª–µ–Ω
    assert scaler.mean_ is not None
    assert len(scaler.mean_) == 2
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è mean
    expected_mean = np.array([3.0, 4.0])
    np.testing.assert_array_almost_equal(scaler.mean_, expected_mean)

def test_standard_scaler_transform(sample_data):
    """–¢–µ—Å—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö."""
    scaler = StandardScaler()
    scaler.fit(sample_data)
    transformed = scaler.transform(sample_data)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º shape
    assert transformed.shape == sample_data.shape
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ mean –±–ª–∏–∑–∫–æ –∫ 0
    assert np.abs(transformed.mean()) < 1e-10

@pytest.mark.parametrize("invalid_data", [
    np.array([]),  # –ü—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
    np.array([1, 2, 3]),  # 1D –º–∞—Å—Å–∏–≤
    None,  # None
])
def test_standard_scaler_invalid_input(invalid_data):
    """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    scaler = StandardScaler()
    
    with pytest.raises(ValueError):
        scaler.fit(invalid_data)
```

Test Coverage:
```bash
# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ —Å coverage
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# –ú–∏–Ω–∏–º—É–º 80% –¥–ª—è merge
# –¶–µ–ª—å: 90%+
```

## –ò—Ç–æ–≥–æ–≤—ã–π checklist –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ML –ø—Ä–æ–µ–∫—Ç–∞

–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º:
- [ ] –°–æ–∑–¥–∞–Ω–∞ –≤–µ—Ç–∫–∞ feature/[name] –∏–ª–∏ experiment/[name]
- [ ] –ü—Ä–æ—á–∏—Ç–∞–Ω–∞ constitution
- [ ] –°–æ–∑–¥–∞–Ω–∞ SPEC.md —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏

Data:
- [ ] –î–∞–Ω–Ω—ã–µ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã (–∏—Å—Ç–æ—á–Ω–∏–∫, —Ä–∞–∑–º–µ—Ä, –∫–∞—á–µ—Å—Ç–≤–æ)
- [ ] Data quality tests –Ω–∞–ø–∏—Å–∞–Ω—ã
- [ ] Train/val/test split –¥–æ preprocessing
- [ ] Random seed –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω (42)
- [ ] DVC –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–µ—Å–ª–∏ –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ)

Code:
- [ ] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ cookiecutter data science
- [ ] Type hints –≤–µ–∑–¥–µ
- [ ] Docstrings –Ω–∞ —Ä—É—Å—Å–∫–æ–º (Google style)
- [ ] pre-commit hooks –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã
- [ ] Tests coverage >= 80%

ML:
- [ ] Baseline –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞
- [ ] EDA –≤—ã–ø–æ–ª–Ω–µ–Ω –∏ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
- [ ] Feature engineering –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
- [ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ MLflow
- [ ] Training curves —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
- [ ] Error analysis –≤—ã–ø–æ–ª–Ω–µ–Ω

Evaluation:
- [ ] Confusion matrix (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
- [ ] Feature importance analysis
- [ ] SHAP values (–¥–ª—è production)
- [ ] –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã

Documentation:
- [ ] README.md –æ–±–Ω–æ–≤–ª—ë–Ω
- [ ] Model card —Å–æ–∑–¥–∞–Ω
- [ ] SPEC.md –∞–∫—Ç—É–∞–ª–µ–Ω
- [ ] –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–æ–±–∞–≤–ª–µ–Ω—ã

Deployment (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):
- [ ] FastAPI endpoint —Å–æ–∑–¥–∞–Ω
- [ ] Docker –æ–±—Ä–∞–∑ —Å–æ–±—Ä–∞–Ω –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω
- [ ] Health check —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Monitoring –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] Rollback strategy –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞

Ethics:
- [ ] Bias detection –≤—ã–ø–æ–ª–Ω–µ–Ω
- [ ] Fairness metrics –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã
- [ ] Limitations –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã
- [ ] Data privacy compliance

Before merge:
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –∑–µ–ª—ë–Ω—ã–µ
- [ ] Code review passed
- [ ] Documentation –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- [ ] CHANGELOG.md –æ–±–Ω–æ–≤–ª—ë–Ω
- [ ] CI/CD pipeline –ø—Ä–æ—à—ë–ª

## Governance
–ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è –∏–º–µ–µ—Ç –≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –≤—Å–µ–º–∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏. –õ—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ –æ–¥–æ–±—Ä–µ–Ω—ã. –í—Å–µ pull request –∏ code review –¥–æ–ª–∂–Ω—ã –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ —ç—Ç–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤. –°–ª–æ–∂–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ–ø—Ä–∞–≤–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–¥—Ö–æ–¥ "–Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ".

**Version**: 1.0.0 | **Ratified**: 2026-02-13 | **Last Amended**: 2026-02-13
